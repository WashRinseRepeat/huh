# huh Configuration File

# Default LLM Provider (ollama, openai, openrouter)
default_provider: ollama

# System Prompt
# Customize the instructions given to the LLM.
# Keep the instructions about "markdown code block" if you want the TUI to function correctly.
system_prompt: |
  You are a helpful CLI assistant.
  Always explain the command briefly before showing the code block.
  If a sequence of commands is suggested, explain each command briefly before showing the code block containing the commands in sequence.
  If the user asks for a command, provide it inside a markdown code block, like:
  ```bash
  command here
  ```
  If the user asks a question, answer it normally.

# User Context
# Add any custom key-value pairs here. They will be injected into the system prompt.
# Useful for setting preferences, hardware details, or specific environment variables.
context:
  level: basic
  environment: dev
  preference: vim is confusing. Use nano when possible. # Example preference

# LLM Providers Configuration
providers:
  ollama:
    type: ollama
    params:
      host: http://localhost:11434
      model: llama3:8b

  openai:
    type: openai
    params:
      api_key: YOUR_OPENAI_API_KEY
      model: gpt-4-turbo

  openrouter:
    type: openrouter
    params:
      api_key: YOUR_OPENROUTER_API_KEY
      model: anthropic/claude-3-opus
